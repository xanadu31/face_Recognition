{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction à la reconnaissance faciale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://www.skillsuccess.com/wp-content/uploads/2018/01/python-image-recognition-2-460x307.jpg\" width = \"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook, nous verrons comment il est possible de créer un algorithme de reconnaissance facial en python.\n",
    "Pour ce faire, nous utiliserons les librairies **face_recognition**, **cv2** et **numpy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre plan est organiser de la manière suivante:\n",
    "\n",
    "1. Importation des librairies\n",
    "2. Chargement et encodages des images\n",
    "3. Détection d'image sur la webcam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I - Importation des librairies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commencera par importer les librairies utiles pour notre projet. Nous utiliserons particulièrement **face_recognition**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "#####                   Algorithme de reconnaissance faciale\n",
    "#############################################################################################\n",
    "##### Imporation des librairies\n",
    "############################################################################################\n",
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#### Lancement de la webcam\n",
    "video_capture = cv2.VideoCapture(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définie ensuite une fonction de chargement des images qui prendra le fichier image en entrée et donnera en sortie un tableau de pixel (**image**) et un encodage de ce tableau (**image_encod**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "#### Fonction de chargement de l'image à reconnaitre \n",
    "##############################################################################################\n",
    "\n",
    "def chargement_image(fichier):\n",
    "    \"\"\"\n",
    "        Entrée:\n",
    "            Le fichier image\n",
    "            \n",
    "        Sortie:\n",
    "            L'image et son encodage\n",
    "    \"\"\"\n",
    "    #### On initialise les tableaux pour les objets \"image\" et \"image_encod\"\n",
    "    image = np.array([])\n",
    "    image_encod = np.array([])\n",
    "    image = face_recognition.load_image_file(fichier)\n",
    "    image_encod = face_recognition.face_encodings(image)[0]\n",
    "    return image, image_encod #### Sortie: Image et Encodage de l'image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II - Chargement et encodages des images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette article, nous utiliserons les images les plus connues en France pour notre algorithme de reconnaissance. La première correspond à celle du **Président Macron**, la seconde est celle du **Premier Ministre Philippe**.\n",
    "Evidemment, ne pouvant pas tester mon algorithme sur ces images, j'y rajouterais modestement la mienne à coté.\n",
    "L'idée de ces deux premiers ajouts étant de **montrer que si l'on dispose de suffisament d'image, il sera possible de détecter celles-ci depuis notre caméra**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <td><img src = \"E_Macron.png\" width = \"200px\" ></td>\n",
    "    <td><img src = \"E_Philippe.png\" width = \"200px\" ></td>\n",
    "    <td><img src = \"Moi.png\" width = \"200px\" ></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On encode les 3 images précedentes pour les rendre compatible avec l'algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### On crée trois nouvelles variables correspondant aux trois visages que l'on souhaite tester.\n",
    "\n",
    "macron_img, macron_encod = chargement_image(\"E_macron.png\")\n",
    "philippe_img, philippe_encod = chargement_image(\"E_Philippe.png\")\n",
    "moi_img, moi_encod = chargement_image(\"moi.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée une liste de ces trois encodages ainsi qu'une liste des trois nom associée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "#### Création de liste d'encoding et de label\n",
    "####################################################################################################\n",
    "\n",
    "visage_connu_encoding = [\n",
    "    moi_encod, \n",
    "    macron_encod,\n",
    "    philippe_encod\n",
    "]\n",
    "\n",
    "nom_visage = [ \"Yacine Aslimi\",\n",
    "                \"Emmanuel Macron\",\n",
    "                \"Edouard Philippe\"\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III - Détection d'image sur la webcam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois les images encodées, il nous reste à les comparer avec le flux de notre webcam. Le script se decompose de la manière suivante:\n",
    "\n",
    "* Lancement de la webcam\n",
    "* Détection des visages sur les images de la webcam\n",
    "* Comparasion de chacune des images de la webcam avec les images prédéfinies\n",
    "* Affichage du résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "#####                       Comparaison des images avec le flux de la webcam\n",
    "#####################################################################################################\n",
    "\n",
    "def activation_reconnaissance_image():\n",
    "    \"\"\"\n",
    "    But: Lancer la webcam et identifier si l'image correspond à une des images définies précédement\n",
    "        Entrée:\n",
    "            Aucune\n",
    "        Sortie:\n",
    "            Video et filtre sur le visage\n",
    "    \"\"\"\n",
    "    \n",
    "    while True:\n",
    "       \n",
    "        # On lance la webcam , le ret correspond et le frame correspond à l'image \n",
    "        ret, frame = video_capture.read()\n",
    "        \n",
    "        #### On convertie les images BGR en RGB\n",
    "        rgb_frame = frame[:, :, ::-1]\n",
    "\n",
    "        \n",
    "        #### Détection de tout les visages sur le frame définie à l'aide de la fonction face_location\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        #### On encode ces visages\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "         #### On boucle sur chacun des frames de la video\n",
    "        \n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "\n",
    "            #### Comparaison entre le visage connu et le frame  \n",
    "            matches = face_recognition.compare_faces(visage_connu_encoding, face_encoding)#### False, False, False...True...False\n",
    "            \"\"\" Dans cette fonction, on compare les visages encodées issues de nos images avec les visages de chacuns des frames issues de notre video\"\"\"\n",
    "            name = \"Inconnu\"\n",
    "\n",
    "            #### Si il ya correspondance entre visage_connu_encoding et les visages issues su frame (visages_encod)\n",
    "\n",
    "            if True in matches:###( liste de true false (ici 3) et on demande s'il ya un true, on prend son index et on applique à la liste des nom de visage pour avoir le nom de l'image)\n",
    "                first_match_index = matches.index(True) ### Numero de l'index (présence dans la liste)\n",
    "                name = nom_visage[first_match_index] #### Application à la liste des nom de visage (index 3)\n",
    "\n",
    "            # Déssine un rectangle sur le frame ou l'image est présente\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "            # Rédaction d'un texte sous le cadre\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "\n",
    "        #### Affiche le résultat de la video\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "       # Taper sur la touche 'q' pour quitter\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "activation_reconnaissance_image()    \n",
    "\n",
    "# Libération de la capture \n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce qui donne les résultats suivants:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><td><img src = \"23_Blog.png\" width = \"400px\" ></td><td><img src = \"31_Blog.png\" width = \"400px\" ></td></table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme arrive bien à **me détecter**!\n",
    "\n",
    "Pour être tout à fait honnete, il faudrait demander à **E.Macron** et **E.Philippe** de tester mon algorithme et ensuite affirmer que mon algorithme est fonctionnel. Comme je manque de temps (mais pas forcement d'ambition), je vous invite à le vérifier par vous même à l'aide du code ci-dessous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithme finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "#####                   Algorithme de reconnaissance faciale\n",
    "#############################################################################################\n",
    "##### Imporation des librairies\n",
    "############################################################################################\n",
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#### Lancement de la webcam\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "##############################################################################################\n",
    "#### Fonction de chargment de l'image à reconnaitre \n",
    "##############################################################################################\n",
    "\n",
    "def chargement_image(fichier):\n",
    "    \"\"\"\n",
    "        Entrée:\n",
    "            Le fichier image\n",
    "            \n",
    "        Sortie:\n",
    "            L'image et son encodage\n",
    "    \"\"\"\n",
    "    #### On initialise les tableaux pour les objets \"image\" et \"image_encod\"\n",
    "    image = np.array([])\n",
    "    image_encod = np.array([])\n",
    "    image = face_recognition.load_image_file(fichier)\n",
    "    image_encod = face_recognition.face_encodings(image)[0]\n",
    "    return image, image_encod #### Sortie: Image et Encodage de l'image\n",
    "\n",
    "#### On crée trois nouvelles variables correspondant aux trois visages que l'on souhaite tester.\n",
    "\n",
    "macron_img, obama_encod = chargement_image(\"E_macron.png\")\n",
    "philippe_img, biden_encod = chargement_image(\"E_Philippe.png\")\n",
    "moi_img, moi_encod = chargement_image(\"Moi.png\")\n",
    "\n",
    "####################################################################################################\n",
    "#### Création de liste d'encoding et de label\n",
    "####################################################################################################\n",
    "\n",
    "visage_connu_encoding = [\n",
    "    moi_encod, \n",
    "    obama_encod,\n",
    "    biden_encod\n",
    "]\n",
    "\n",
    "nom_visage = [ \"Yacine Aslimi\",\n",
    "                \"Emmanuel Macron\",\n",
    "                \"Edouard Philippe\"\n",
    "             ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "#####                       Comparaison des images avec le flux de la webcam\n",
    "#####################################################################################################\n",
    "\n",
    "def activation_reconnaissance_image():\n",
    "    \"\"\"\n",
    "    But: Lancer la webcam et identifier si l'image correspond à une des images définie précédement\n",
    "        Entrée:\n",
    "            Aucune\n",
    "        Sortie:\n",
    "            Video et filtre sur le visage\n",
    "    \"\"\"\n",
    "    \n",
    "    while True:\n",
    "       \n",
    "        # On lance la webcam , le ret correspond et le frame correspond à l'image \n",
    "        ret, frame = video_capture.read()\n",
    "        \n",
    "        #### On convertie les images BGR en RGB\n",
    "        rgb_frame = frame[:, :, ::-1]\n",
    "\n",
    "        \n",
    "        #### Détection de tout les visages sur le frame définie à l'aide de la fonction face_location\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        #### On encode ces visages\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "         #### On boucle sur chacun des frames de la video\n",
    "        \n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "\n",
    "            #### Comparaison entre le visage connu et le frame  \n",
    "            matches = face_recognition.compare_faces(visage_connu_encoding, face_encoding)#### False, False, False...True...False\n",
    "            \"\"\" Dans cette fonction, on compare les visages encodées issues de nos images avec les visages de chacuns des frames issues de notre video\"\"\"\n",
    "            name = \"Inconnu\"\n",
    "\n",
    "            #### Si il ya correspondance entre visage_connu_encoding et les visages issues su frame (visages_encod)\n",
    "\n",
    "            if True in matches:###( liste de true false (ici 3) et on demande s'il ya un true, on prend son index et on applique à la liste des nom de visage pour avoir le nom de l'image)\n",
    "                first_match_index = matches.index(True) ### Numero de l'index (présence dans la liste)\n",
    "                name = nom_visage[first_match_index] #### Application à la liste des nom de visage (index 3)\n",
    "\n",
    "            # Déssine un rectangle sur le frame ou l'image est présente\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "            # Rédaction d'un texte sous le cadre\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "\n",
    "        #### Affiche le résultat de la video\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "       # Taper sur la touche 'q' pour quitter\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "activation_reconnaissance_image()    \n",
    "\n",
    "# Libération de la capture \n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
